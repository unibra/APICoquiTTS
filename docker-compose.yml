services:
  tts-api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: tts-api
    restart: unless-stopped
    # Runtime nvidia será usado se disponível, senão fallback para runc
    runtime: nvidia  # Remova esta linha se não tiver GPU
    environment:
      - PYTHONUNBUFFERED=1
      - COQUI_TOS_AGREED=1
      - DEBUG=False
      - LOG_LEVEL=INFO
      - FORCE_CPU=false
      - TTS_DEVICE=auto
      - TTS_CACHE_PATH=/app/models
      - HF_HOME=/app/models
      - TRANSFORMERS_CACHE=/app/models
      - HUGGINGFACE_HUB_CACHE=/app/models
      - HF_HUB_CACHE=/app/models
      - TOKENIZERS_PARALLELISM=false
      # Variáveis GPU (serão ignoradas se GPU não disponível)
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=0
      - CUDA_VERSION=12.1
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True,roundup_power2_divisions:True,garbage_collection_threshold:0.6
      - CUDA_LAUNCH_BLOCKING=0
      - TORCH_CUDNN_V8_API_ENABLED=1
      - TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1
      - CUDA_MODULE_LOADING=LAZY
      - NVCC_PREPEND_FLAGS=--compiler-options -fPIC
    ports:
      - "8888:8888"
    volumes:
      - tts_models:/app/models
      - tts_output:/app/output
      - /etc/localtime:/etc/localtime:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8888/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 180s  # Mais tempo para fallback CPU
    networks:
      - tts-net

# Volumes para persistência
volumes:
  tts_models:
    driver: local
  tts_output:
    driver: local

# Network isolada
networks:
  tts-net:
    driver: bridge