# Coqui TTS API Service com CUDA

Servi√ßo de Text-to-Speech (TTS) usando Coqui TTS, FastAPI e Docker Compose com acelera√ß√£o CUDA.

## Funcionalidades

- üé§ Convers√£o de texto em √°udio usando modelos Coqui TTS
- üöÄ Acelera√ß√£o GPU com CUDA 12.1
- üöÄ API REST com FastAPI
- üê≥ Containeriza√ß√£o com Docker
- üìä Documenta√ß√£o autom√°tica da API
- üîß Configura√ß√£o flex√≠vel de modelos e vozes
- üìà Health checks e monitoramento
- ‚ö° PyTorch 2.4.1 com CUDA 12.1
- üî• Suporte a Tensor Cores modernas

**Otimiza√ß√µes GPU:**
- **Base Python 3.11** - Com cuDNN 9.11.0 e CUDA 12.1
- **PyTorch 2.4.1+cu121** - Alinhado com outros servi√ßos
- **Tensor Cores** - Habilitado com `allow_tf32=True`
- **Precis√£o mista** - `torch.set_float32_matmul_precision('high')`
- **Benchmark autom√°tico** - `torch.backends.cudnn.benchmark = True`
- **Gerenciamento de mem√≥ria** - Cache otimizado e limpeza autom√°tica

**Recursos GPU:**
- Monitoramento em tempo real (uso, temperatura, mem√≥ria)
- Detec√ß√£o autom√°tica de capacidade computacional
- Logs detalhados das configura√ß√µes GPU
- Runtime NVIDIA com isolamento adequado
- Cache inteligente de modelos HuggingFace
- Configura√ß√µes otimizadas do PyTorch CUDA

**Performance:**
- PyTorch 2.4.1 com CUDA 12.1
- Bibliotecas otimizadas (nvidia-ml-py3, GPUtil)
- Cache inteligente de modelos
- Processamento paralelo otimizado

Para usar com acelera√ß√£o GPU, certifique-se de ter:
1. NVIDIA Docker instalado (`nvidia-docker2`)
2. Drivers NVIDIA atualizados (535.86.10+)
3. Docker Compose 3.8+ com suporte GPU

## Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py           # Aplica√ß√£o FastAPI
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt  # Depend√™ncias Python
‚îú‚îÄ‚îÄ Dockerfile            # Imagem Docker
‚îú‚îÄ‚îÄ docker-compose.yml    # Orquestra√ß√£o de containers
‚îî‚îÄ‚îÄ README.md            # Este arquivo
```

## Como Usar

### Pr√©-requisitos

- Docker com runtime NVIDIA instalado
- GPU NVIDIA com CUDA support
- Driver NVIDIA 525.60.13 ou superior
- Docker Compose 3.8+

### 1. Construir e Executar com Docker Compose

```bash
# Construir e iniciar os servi√ßos
docker-compose up -d

# Verificar logs
docker-compose logs -f tts-api

# Parar os servi√ßos
docker-compose down
```

### 2. Acessar a API

- **API Docs**: http://localhost:8888/docs
- **Health Check**: http://localhost:8888/health
- **Modelos Dispon√≠veis**: http://localhost:8888/models

### 3. Usar o Endpoint TTS

#### Exemplo com curl:

```bash
curl -X POST "http://localhost:8888/tts" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Ol√°, este √© um teste do servi√ßo TTS!",
    "model_name": "tts_models/en/ljspeech/tacotron2-DDC"
  }' \
  --output audio.wav
```

#### Exemplo com Python:

```python
import requests

url = "http://localhost:8888/tts"
data = {
    "text": "Ol√° mundo! Este √© um teste do Coqui TTS.",
    "model_name": "tts_models/en/ljspeech/tacotron2-DDC"
}

response = requests.post(url, json=data)

if response.status_code == 200:
    with open("output.wav", "wb") as f:
        f.write(response.content)
    print("√Åudio gerado com sucesso!")
else:
    print(f"Erro: {response.status_code}")
```

## Par√¢metros da API

### POST /tts

- `text` (obrigat√≥rio): Texto a ser convertido em √°udio
- `model_name` (opcional): Nome do modelo TTS
- `speaker` (opcional): Nome do speaker/voz
- `language` (opcional): C√≥digo do idioma

### Modelos Suportados

Para ver todos os modelos dispon√≠veis, acesse: `GET /models`

Alguns modelos populares:
- `tts_models/en/ljspeech/tacotron2-DDC`
- `tts_models/pt/cv/vits`
- `tts_models/es/mai/tacotron2-DDC`

## Configura√ß√£o

### Vari√°veis de Ambiente

- `TTS_CACHE_PATH`: Caminho para cache de modelos (padr√£o: `/app/models`)
- `PYTHONUNBUFFERED`: Para logs em tempo real

### Volumes

- `./models:/app/models`: Cache persistente de modelos TTS
- `./output:/app/output`: Diret√≥rio para arquivos de sa√≠da (opcional)

## Desenvolvimento Local

### Sem Docker:

```bash
# Instalar depend√™ncias
pip install -r app/requirements.txt

# Executar aplica√ß√£o
cd app
python main.py
```

### Com Docker apenas:

```bash
# Construir imagem
docker build -t coqui-tts-api .

# Executar container
docker run -p 8888:8888 coqui-tts-api
```

## Troubleshooting

### Problemas Comuns:

1. **Modelo n√£o carrega**: Verifique se h√° espa√ßo suficiente em disco
2. **Erro de depend√™ncias**: Rebuild a imagem Docker
3. **Mem√≥ria insuficiente**: Aumente os recursos do Docker

### Logs:

```bash
# Ver logs da API
docker-compose logs tts-api
```

## Produ√ß√£o

Para produ√ß√£o, considere:

- Usar um modelo TTS mais r√°pido
- Implementar cache de √°udio
- Adicionar autentica√ß√£o (pode ser feito via Cloudflare Access)
- Configurar rate limiting
- Usar HTTPS (via Cloudflared tunnel)
- Implementar m√©tricas e monitoramento

## Licen√ßa

Este projeto usa Coqui TTS, que est√° sob licen√ßa MPL 2.0.