from fastapi import FastAPI, HTTPException
from fastapi import File, UploadFile, Form
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import io
import logging
from typing import Optional
import uvicorn
import torch
import os
import psutil
import threading
import time
import tempfile
import shutil
from pathlib import Path

try:
    from TTS.api import TTS
    import GPUtil
except ImportError:
    TTS = None
    GPUtil = None

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configura√ß√µes de otimiza√ß√£o para RTX 5090
def setup_gpu_optimization():
    """Configurar otimiza√ß√µes espec√≠ficas para RTX 5090"""
    if torch.cuda.is_available():
        try:
            # Obter informa√ß√µes da GPU
            gpu_info = torch.cuda.get_device_properties(0)
            compute_capability = f"sm_{gpu_info.major}{gpu_info.minor}"
            
            logger.info(f"GPU detectada: {gpu_info.name}")
            logger.info(f"Mem√≥ria GPU: {gpu_info.total_memory / 1024**3:.1f} GB")
            logger.info(f"Compute Capability: {gpu_info.major}.{gpu_info.minor} ({compute_capability})")
            logger.info(f"CUDA Version: {torch.version.cuda}")
            
            # Verificar se a arquitetura √© suportada pelo PyTorch
            supported_archs = torch.cuda.get_arch_list()
            logger.info(f"Arquiteturas CUDA suportadas pelo PyTorch: {supported_archs}")
            
            # Verificar se a capacidade computacional est√° nas arquiteturas suportadas
            arch_supported = any(compute_capability in arch for arch in supported_archs)
            
            if not arch_supported:
                logger.warning(f"‚ö†Ô∏è  Arquitetura {compute_capability} n√£o est√° explicitamente suportada")
                logger.warning("üîÑ Fazendo fallback para CPU para evitar erros CUDA")
                return False
            
            # Testar uma opera√ß√£o simples na GPU para verificar compatibilidade real
            try:
                test_tensor = torch.tensor([1.0]).cuda()
                result = test_tensor * 2
                result.cpu()  # Mover de volta para CPU
                del test_tensor, result
                torch.cuda.empty_cache()
                logger.info("‚úÖ Teste CUDA bem-sucedido!")
            except Exception as cuda_test_error:
                logger.error(f"‚ùå Teste CUDA falhou: {cuda_test_error}")
                logger.warning("üîÑ Fazendo fallback para CPU")
                return False
            
            # Configurar otimiza√ß√µes GPU se tudo estiver OK
            torch.backends.cudnn.benchmark = True
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            
            # Configura√ß√µes espec√≠ficas do ambiente
            os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
            os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # Para performance
            
            # Configurar precision otimizada
            torch.set_float32_matmul_precision('high')
            torch.cuda.empty_cache()
            
            logger.info("üöÄ Otimiza√ß√µes GPU ativadas com sucesso!")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao configurar GPU: {e}")
            logger.warning("üîÑ Fazendo fallback para CPU")
            return False
    return False

# Configurar GPU na inicializa√ß√£o
gpu_available = setup_gpu_optimization()

app = FastAPI(
    title="Coqui TTS API",
    description="Servi√ßo de Text-to-Speech usando Coqui TTS otimizado para NVIDIA RTX 5090",
    version="1.0.0"
)

# Modelo de request
class TTSRequest(BaseModel):
    model_config = {"protected_namespaces": ()}
    
    text: str
    model_name: Optional[str] = "tts_models/multilingual/multi-dataset/xtts_v2"
    speaker: Optional[str] = None
    language: Optional[str] = "pt"
    use_gpu: Optional[bool] = True
    speed: Optional[float] = 1.0

# Modelo para clonagem de voz
class VoiceCloneRequest(BaseModel):
    model_config = {"protected_namespaces": ()}
    
    text: str
    language: Optional[str] = "pt"
    use_gpu: Optional[bool] = True
# Vari√°vel global para armazenar o modelo TTS
tts_model = None

@app.on_event("startup")
async def startup_event():
    """Inicializar o modelo TTS na inicializa√ß√£o da aplica√ß√£o"""
    global tts_model
    
    if TTS is None:
        logger.error("Coqui TTS n√£o est√° instalado. Instale com: pip install TTS")
        return
    
    try:
        # Inicializar com modelo XTTS v2 para Portugu√™s do Brasil
        default_model = "tts_models/multilingual/multi-dataset/xtts_v2"
        logger.info(f"Carregando modelo TTS: {default_model}")
        
        # Configurar device (GPU se dispon√≠vel)
        device = "cuda" if gpu_available else "cpu"
        logger.info(f"Usando device: {device}")
        
        tts_model = TTS(model_name=default_model).to(device)
        logger.info("Modelo XTTS v2 para Portugu√™s do Brasil carregado com sucesso!")
        
        if gpu_available:
            logger.info("Otimiza√ß√µes GPU ativadas!")
        else:
            logger.info("Usando CPU para processamento TTS")
    except Exception as e:
        logger.error(f"Erro ao carregar modelo TTS: {e}")

@app.get("/")
async def root():
    """Endpoint raiz com informa√ß√µes sobre a API"""
    return {
        "message": "Coqui TTS API est√° funcionando!",
        "docs": "/docs",
        "version": "1.0.0"
    }

@app.get("/health")
async def health_check():
    """Verifica√ß√£o de sa√∫de da aplica√ß√£o"""
    gpu_info = {}
    if gpu_available and GPUtil:
        try:
            gpus = GPUtil.getGPUs()
            if gpus:
                gpu = gpus[0]
                gpu_info = {
                    "name": gpu.name,
                    "memory_used": f"{gpu.memoryUsed}MB",
                    "memory_total": f"{gpu.memoryTotal}MB",
                    "gpu_load": f"{gpu.load*100:.1f}%",
                    "temperature": f"{gpu.temperature}¬∞C"
                }
        except Exception as e:
            logger.warning(f"Erro ao obter informa√ß√µes da GPU: {e}")
    
    return {
        "status": "healthy",
        "tts_available": tts_model is not None,
        "gpu_available": gpu_available,
        "device": "cuda" if gpu_available else "cpu",
        "gpu_info": gpu_info
    }

@app.get("/models")
async def list_models():
    """Listar modelos TTS dispon√≠veis"""
    if TTS is None:
        raise HTTPException(status_code=500, detail="Coqui TTS n√£o est√° dispon√≠vel")
    
    try:
        logger.info("Tentando listar modelos TTS dispon√≠veis...")
        # Criar inst√¢ncia tempor√°ria para acessar lista de modelos
        temp_tts = TTS()
        models = temp_tts.list_models()
        logger.info(f"Encontrados {len(models) if models else 0} modelos")
        return {"available_models": models or []}
    except Exception as e:
        logger.error(f"Erro ao listar modelos: {e}", exc_info=True)
        # Fallback com modelos conhecidos - priorizando XTTS v2 e portugu√™s brasileiro
        fallback_models = [
            "tts_models/multilingual/multi-dataset/xtts_v2",
            "tts_models/pt/cv/vits",
            "tts_models/en/ljspeech/tacotron2-DDC",
            "tts_models/en/ljspeech/glow-tts",
            "tts_models/pt/cv/tacotron2-DDC",
            "tts_models/fr/mai/tacotron2-DDC",
            "tts_models/es/mai/tacotron2-DDC",
            "tts_models/de/mai/tacotron2-DDC"
        ]
        logger.info(f"Retornando lista de modelos conhecidos como fallback: {len(fallback_models)} modelos")
        return {
            "available_models": fallback_models,
            "note": "Lista de fallback - alguns modelos podem n√£o estar dispon√≠veis",
            "error": str(e)
        }

@app.post("/tts")
async def text_to_speech(request: TTSRequest):
    """
    Converter texto em √°udio usando Coqui TTS
    
    - **text**: Texto a ser convertido em √°udio
    - **model_name**: Nome do modelo TTS a ser usado (opcional)
    - **speaker**: Nome do speaker/voz (opcional, depende do modelo)
    - **language**: C√≥digo do idioma (opcional)
    """
    if TTS is None:
        raise HTTPException(status_code=500, detail="Coqui TTS n√£o est√° dispon√≠vel")
    
    if not request.text.strip():
        raise HTTPException(status_code=400, detail="Texto n√£o pode estar vazio")
    
    try:
        # Usar modelo global ou carregar um novo se especificado
        current_tts = tts_model
        if request.model_name and request.model_name != "tts_models/multilingual/multi-dataset/xtts_v2":
            logger.info(f"Carregando modelo espec√≠fico: {request.model_name}")
            device = "cuda" if (gpu_available and request.use_gpu) else "cpu"
            current_tts = TTS(model_name=request.model_name).to(device)
        
        if current_tts is None:
            raise HTTPException(status_code=500, detail="Modelo TTS n√£o est√° carregado")
        
        # Gerar √°udio
        device = "cuda" if (gpu_available and request.use_gpu) else "cpu"
        logger.info(f"Gerando √°udio para texto: {request.text[:50]}... (device: {device})")
        
        # Medir tempo de infer√™ncia
        start_time = time.time()
        
        # Verificar se o modelo suporta m√∫ltiplos speakers
        try:
            # Tentar obter informa√ß√µes sobre speakers do modelo
            speakers = getattr(current_tts, 'speakers', None)
            is_multi_speaker = speakers is not None and len(speakers) > 0
            
            # Gerar √°udio com par√¢metros apropriados
            tts_kwargs = {"text": request.text}
            
            # Adicionar speaker apenas se o modelo suportar e foi especificado
            if is_multi_speaker and request.speaker:
                tts_kwargs["speaker"] = request.speaker
                logger.info(f"Usando speaker: {request.speaker}")
            
            # Adicionar language se especificado
            if request.language:
                tts_kwargs["language"] = request.language
                logger.info(f"Usando idioma: {request.language} (Portugu√™s do Brasil para 'pt')")
            
            logger.info(f"Par√¢metros TTS: {tts_kwargs}")
            wav_data = current_tts.tts(**tts_kwargs)
            
        except Exception as tts_error:
            logger.error(f"Erro espec√≠fico do TTS: {tts_error}")
            # Fallback - tentar apenas com texto
            logger.info("Tentando fallback apenas com texto...")
            wav_data = current_tts.tts(text=request.text)
        
        inference_time = time.time() - start_time
        logger.info(f"√Åudio gerado em {inference_time:.2f} segundos")
        
        # Criar buffer em mem√≥ria para o √°udio
        audio_buffer = io.BytesIO()
        
        # Converter para bytes e escrever no buffer
        import soundfile as sf
        import numpy as np
        
        # Converter para numpy array se necess√°rio
        if not isinstance(wav_data, np.ndarray):
            wav_data = np.array(wav_data)
        
        # Escrever no buffer como WAV
        sf.write(audio_buffer, wav_data, 22050, format='WAV')
        audio_buffer.seek(0)
        
        logger.info("√Åudio gerado com sucesso!")
        
        # Retornar como streaming response
        return StreamingResponse(
            io.BytesIO(audio_buffer.read()),
            media_type="audio/wav",
            headers={"Content-Disposition": "attachment; filename=tts_output.wav"}
        )
    except Exception as e:
        logger.error(f"Erro ao gerar √°udio: {e}")
        raise HTTPException(status_code=500, detail=f"Erro ao gerar √°udio: {str(e)}")

@app.post("/tts-simple")
async def simple_text_to_speech(text: str):
    """
    Vers√£o simplificada do endpoint TTS - apenas recebe texto como par√¢metro
    """
    request = TTSRequest(text=text)
    return await text_to_speech(request)

@app.post("/tts-clone")
async def voice_cloning_tts(
    text: str = Form(...),
    language: str = Form("pt"),
    use_gpu: bool = Form(True),
    speaker_audio: UploadFile = File(...)
):
    """
    üé≠ Clone de Voz com XTTS v2
    
    Gera √°udio usando a voz de refer√™ncia fornecida (zero-shot voice cloning).
    
    - **text**: Texto a ser convertido em √°udio
    - **language**: C√≥digo do idioma (pt para Portugu√™s do Brasil)
    - **use_gpu**: Usar GPU para processamento (se dispon√≠vel)
    - **speaker_audio**: Arquivo de √°udio com a voz de refer√™ncia (WAV, MP3, etc.)
    
    üìã Requisitos para o √°udio de refer√™ncia:
    - Dura√ß√£o: 6-12 segundos (ideal)
    - Qualidade: Limpo, sem ru√≠do
    - Formato: WAV, MP3, M4A, FLAC
    - Conte√∫do: Apenas uma pessoa falando
    """
    logger.info(f"üé≠ Iniciando clone de voz - Texto: '{text[:50]}...', Idioma: {language}")
    
    if not text.strip():
        raise HTTPException(status_code=400, detail="Texto n√£o pode estar vazio")
    
    if TTS is None:
        raise HTTPException(status_code=500, detail="Coqui TTS n√£o est√° dispon√≠vel")
    
    # Verificar se temos um modelo carregado
    if tts_model is None:
        raise HTTPException(status_code=500, detail="Modelo TTS n√£o est√° carregado. Tente novamente em alguns segundos.")
    
    # Validar tipo de arquivo
    logger.info(f"üìÅ Arquivo recebido - Nome: {speaker_audio.filename}, Tipo: {speaker_audio.content_type}, Tamanho: {speaker_audio.size if hasattr(speaker_audio, 'size') else 'Desconhecido'}")
    
    # Verificar extens√£o do arquivo se o content_type n√£o estiver dispon√≠vel
    valid_extensions = ['.wav', '.mp3', '.m4a', '.flac', '.ogg', '.aac']
    if speaker_audio.filename:
        file_ext = Path(speaker_audio.filename).suffix.lower()
        if not (speaker_audio.content_type and speaker_audio.content_type.startswith('audio/')) and file_ext not in valid_extensions:
            raise HTTPException(
                status_code=400, 
                detail=f"Arquivo deve ser de √°udio. Extens√µes suportadas: {', '.join(valid_extensions)}"
            )
    
    # Criar arquivo tempor√°rio para o √°udio de refer√™ncia
    temp_audio_path = None
    try:
        logger.info("üìÅ Criando arquivo tempor√°rio para √°udio de refer√™ncia...")
        
        # Criar arquivo tempor√°rio
        file_suffix = Path(speaker_audio.filename).suffix if speaker_audio.filename else '.wav'
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_suffix) as temp_file:
            logger.info(f"üìÅ Copiando conte√∫do para: {temp_file.name}")
            # Copiar conte√∫do do upload para o arquivo tempor√°rio
            shutil.copyfileobj(speaker_audio.file, temp_file)
            temp_audio_path = temp_file.name
        
        # Verificar se o arquivo foi criado e tem conte√∫do
        if not Path(temp_audio_path).exists():
            raise Exception("Falha ao criar arquivo tempor√°rio")
        
        file_size = Path(temp_audio_path).stat().st_size
        logger.info(f"‚úÖ Arquivo tempor√°rio criado: {temp_audio_path} (tamanho: {file_size} bytes)")
        
        if file_size == 0:
            raise Exception("Arquivo de √°udio est√° vazio")
        
        logger.info(f"üé≠ Gerando clone de voz para: '{text[:50]}...'")
        
        # Verificar se o modelo suporta clonagem de voz
        model_name = getattr(tts_model, 'model_name', 'Unknown')
        logger.info(f"ü§ñ Usando modelo: {model_name}")
        
        # Verificar se √© XTTS v2 ou modelo compat√≠vel
        if 'xtts' not in model_name.lower():
            logger.warning(f"‚ö†Ô∏è  Modelo atual ({model_name}) pode n√£o suportar clonagem de voz otimamente")
        
        # Medir tempo de infer√™ncia
        start_time = time.time()
        
        logger.info(f"üîß Par√¢metros TTS:")
        logger.info(f"   - Texto: '{text[:50]}...'")
        logger.info(f"   - Idioma: {language}")
        logger.info(f"   - Arquivo de refer√™ncia: {temp_audio_path}")
        logger.info(f"   - Device: {'cuda' if gpu_available else 'cpu'}")
        
        try:
            # XTTS v2 suporta clonagem com speaker_wav
            logger.info("üéµ Executando s√≠ntese TTS com clonagem...")
            wav_data = tts_model.tts(
                text=text,
                speaker_wav=temp_audio_path,
                language=language
            )
            logger.info("‚úÖ S√≠ntese TTS conclu√≠da com sucesso!")
            
        except Exception as tts_error:
            logger.error(f"‚ùå Erro na s√≠ntese TTS: {type(tts_error).__name__}: {str(tts_error)}")
            # Tentar fallback sem especificar language
            logger.info("üîÑ Tentando fallback sem par√¢metro language...")
            try:
                wav_data = tts_model.tts(
                    text=text,
                    speaker_wav=temp_audio_path
                )
                logger.info("‚úÖ Fallback bem-sucedido!")
            except Exception as fallback_error:
                logger.error(f"‚ùå Fallback tamb√©m falhou: {type(fallback_error).__name__}: {str(fallback_error)}")
                raise Exception(f"Erro na s√≠ntese TTS: {str(tts_error)}. Fallback: {str(fallback_error)}")
        
        inference_time = time.time() - start_time
        logger.info(f"‚è±Ô∏è  √Åudio gerado em {inference_time:.2f} segundos")
        
        # Verificar se temos dados de √°udio
        if wav_data is None:
            raise Exception("Modelo retornou dados vazios")
        
        logger.info(f"üìä Dados de √°udio: tipo={type(wav_data)}, shape={getattr(wav_data, 'shape', 'N/A')}")
        
        # Criar buffer em mem√≥ria para o √°udio
        logger.info("üíæ Convertendo √°udio para formato WAV...")
        audio_buffer = io.BytesIO()
        
        # Converter para bytes e escrever no buffer
        import soundfile as sf
        import numpy as np
        
        # Converter para numpy array se necess√°rio
        if not isinstance(wav_data, np.ndarray):
            logger.info("üîÑ Convertendo dados para numpy array...")
            wav_data = np.array(wav_data)
        
        # Verificar se temos dados v√°lidos
        if len(wav_data) == 0:
            raise Exception("Dados de √°udio est√£o vazios ap√≥s convers√£o")
        
        logger.info(f"üìä Array final: shape={wav_data.shape}, dtype={wav_data.dtype}")
        
        # Escrever no buffer como WAV
        sample_rate = 22050  # Taxa de amostragem padr√£o do XTTS v2
        sf.write(audio_buffer, wav_data, sample_rate, format='WAV')
        audio_buffer.seek(0)
        
        # Verificar tamanho do buffer
        buffer_size = audio_buffer.getbuffer().nbytes
        logger.info(f"üíæ Buffer de √°udio criado: {buffer_size} bytes")
        
        if buffer_size == 0:
            raise Exception("Buffer de √°udio est√° vazio")
        
        logger.info("üéâ Clone de voz gerado com sucesso! üé≠")
        
        # Retornar como streaming response
        return StreamingResponse(
            io.BytesIO(audio_buffer.read()),
            media_type="audio/wav",
            headers={"Content-Disposition": "attachment; filename=voice_clone_output.wav"}
        )
        
    except Exception as e:
        error_msg = f"{type(e).__name__}: {str(e)}"
        logger.error(f"‚ùå Erro ao gerar clone de voz: {error_msg}")
        logger.error(f"üìç Detalhes do erro:", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erro ao gerar clone de voz: {error_msg}")
    
    finally:
        # Limpar arquivo tempor√°rio
        if temp_audio_path and Path(temp_audio_path).exists():
            try:
                Path(temp_audio_path).unlink()
                logger.info(f"üóëÔ∏è  Arquivo tempor√°rio removido: {temp_audio_path}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Erro ao remover arquivo tempor√°rio: {e}")

@app.get("/clone-info")
async def voice_clone_info():
    """
    üìñ Informa√ß√µes sobre a funcionalidade de clonagem de voz
    """
    return {
        "feature": "Voice Cloning com XTTS v2",
        "description": "Clone qualquer voz usando apenas 6-12 segundos de √°udio de refer√™ncia",
        "endpoint": "/tts-clone",
        "method": "POST",
        "supported_languages": [
            "pt - Portugu√™s (Brasil)",
            "en - English",
            "es - Espa√±ol", 
            "fr - Fran√ßais",
            "de - Deutsch",
            "it - Italiano",
            "ja - Êó•Êú¨Ë™û",
            "ko - ÌïúÍµ≠Ïñ¥",
            "zh - ‰∏≠Êñá",
            "ar - ÿßŸÑÿπÿ±ÿ®Ÿäÿ©",
            "tr - T√ºrk√ße",
            "pl - Polski",
            "nl - Nederlands",
            "cs - ƒåe≈°tina",
            "ru - –†—É—Å—Å–∫–∏–π",
            "hu - Magyar",
            "hi - ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä"
        ],
        "audio_requirements": {
            "duration": "6-12 segundos (ideal)",
            "quality": "Limpo, sem ru√≠do de fundo",
            "formats": ["WAV", "MP3", "M4A", "FLAC"],
            "content": "Apenas uma pessoa falando",
            "language_match": "Preferencialmente no mesmo idioma de sa√≠da"
        },
        "tips": [
            "Use √°udios com boa qualidade para melhores resultados",
            "Evite m√∫sica ou ru√≠do de fundo no √°udio de refer√™ncia",
            "6-12 segundos √© o tempo ideal - nem muito curto, nem muito longo",
            "A voz clonada funcionar√° melhor no mesmo idioma do √°udio original"
        ]
    }

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8888)